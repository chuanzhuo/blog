{"title":"用Docker部署大语言模型Llama 3","slug":"用Docker部署大语言模型Llama-3","date":"2024-04-21T08:38:43.000Z","updated":"2025-11-27T13:18:18.182Z","comments":true,"path":"api/articles/用Docker部署大语言模型Llama-3.json","excerpt":" [Figure] AI, 大语言模型","covers":["https://img.carlzeng.com:3/i/2025/11/27/692841a55d698.png","https://img.carlzeng.com:3/i/2025/11/21/6920195f995a9.png","https://img.carlzeng.com:3/i/2025/11/21/692046c34be1e.png","https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png"],"content":"<img class=\"lozad\" data-src=\"https://img.carlzeng.com:3/i/2025/11/27/692841a55d698.png\">\n\n<p>AI, 大语言模型</p>\n<span id=\"more\"></span>\n\n<div> \n<button onclick=\"synthesizeSpeech()\">朗读全文</button>\n</div>\n<audio controls id=\"audioPlayer\">Your browser does not support the audio element.</audio>      \n<script>\n  function synthesizeSpeech() { \n    var inputText = document.getElementsByClassName('post-block')[0].innerText;\n    var voice = \"ZH\";\n    var url = 'https://tts.carlzeng.com:3/speech?text=' + encodeURIComponent(inputText.substring(0,3000)) + '&voice=' + voice;\n    var audioPlayer = document.getElementById('audioPlayer');          \n    audioPlayer.src = url;\n    audioPlayer.load();\n    audioPlayer.play();\n  }\n</script>\n\n\n\n\n<h1 id=\"有什么用\"><a href=\"#有什么用\" class=\"headerlink\" title=\"有什么用\"></a>有什么用</h1><p>体验一下AI目前在CPU上运行的应用; 用来学习AI大语言模型</p>\n<p>本文被停滞了将近1年半时间; 受制于硬件和时间关系; 即便最近跑通了也更尴尬. 只要一请求打一点的运算, CPU马上100%占用. 下一步: 安排英伟达的GPU登场</p>\n<h1 id=\"怎么用\"><a href=\"#怎么用\" class=\"headerlink\" title=\"怎么用\"></a>怎么用</h1><h2 id=\"拉取Ollama镜像命令\"><a href=\"#拉取Ollama镜像命令\" class=\"headerlink\" title=\"*拉取Ollama镜像命令\"></a>*拉取Ollama镜像命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker  pull ollama/ollama:latest</span><br></pre></td></tr></table></figure>\n\n<p>然后在bash命令界面,执行<code>ollama run llama2</code>命令，接着等待下载即可,最后出现success,表示下载运行Llama 2模型成功</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it ollama-ollama1 bash    </span><br><span class=\"line\">root@ollama-ollama1:/# ollama run llama2                                                                  </span><br><span class=\"line\">pulling manifest                                                                                          </span><br><span class=\"line\">pulling 8934d96d3f08...  89% ▕█████████████████████████████████████     ▏ 3.4 GB/3.8 GB  4.8 MB/s   1m26s</span><br></pre></td></tr></table></figure>\n\n<p>教程：<a href=\"https://github.com/ollama/ollama\">https://github.com/ollama/ollama</a></p>\n<p>Remove a model<br>    ollama rm llama2</p>\n<p>卡死；删除整个container，空间没有得到释放，郁闷。。。</p>\n<p>20240423放弃，因为对CPU的占用太大。</p>\n<h2 id=\"拉取Chatbot-Ollama（这是UI）镜像命令\"><a href=\"#拉取Chatbot-Ollama（这是UI）镜像命令\" class=\"headerlink\" title=\"*拉取Chatbot-Ollama（这是UI）镜像命令\"></a>*拉取Chatbot-Ollama（这是UI）镜像命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker  pull ghcr.io/ivanfioravanti/chatbot-ollama:main</span><br></pre></td></tr></table></figure>\n\n<p>然后设置这个UI的一个变量：该变量就是连接我们上面运行Ollama框架服务的地址,我们设置本地地址:</p>\n<p>http:&#x2F;&#x2F;群晖局域网IP:11434</p>\n<h1 id=\"相关内容\"><a href=\"#相关内容\" class=\"headerlink\" title=\"相关内容\"></a>相关内容</h1><iframe style=\"box-shadow: 0px 0px 20px -10px;\" src=\"https://query.carlzeng.com:3/appsearch?q=ai\" frameborder=\"0\" scrolling=\"auto\" width=\"100%\" height=\"500\"></iframe>\n\n<h1 id=\"实现方法\"><a href=\"#实现方法\" class=\"headerlink\" title=\"实现方法\"></a>实现方法</h1><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">localai:</span></span><br><span class=\"line\">        <span class=\"attr\">tty:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">stdin_open:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">local-ai</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8105</span><span class=\"string\">:8080</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">localai/localai:latest-aio-cpu</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">~/models:/models:cached</span></span><br></pre></td></tr></table></figure>\n\n<p>运行之前: </p>\n<p><img data-src=\"https://img.carlzeng.com:3/i/2025/11/21/6920195f995a9.png\" alt=\"image-20251121154835867\"></p>\n<p>运行之后: </p>\n<p><img data-src=\"https://img.carlzeng.com:3/i/2025/11/21/692046c34be1e.png\" alt=\"image-20251121190221555\"></p>\n<p>可见CPU直接飙满了~. 还好当没有请求的时候cpu不是一直这样保持爆满的状态</p>\n<p>curl <a href=\"http://192.168.6.117:8105/tts\">http://192.168.6.117:8105/tts</a> -H “Content-Type: application&#x2F;json” -d ‘{<br>  “input”: “Hello world”,<br>  “model”: “tts”<br>}’</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Load model from /models/tts failed:Load model /models/tts failed. File doesn&#x27;t exist&quot;</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"CPU-only\"><a href=\"#CPU-only\" class=\"headerlink\" title=\"CPU only\"></a>CPU only</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">version: &quot;3&quot;</span><br><span class=\"line\">services:</span><br><span class=\"line\">    ollama:</span><br><span class=\"line\">        volumes:</span><br><span class=\"line\">            - ./ollama:/root/.ollama</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">            - 8106:11434</span><br><span class=\"line\">        container_name: ollama</span><br><span class=\"line\">        image: ollama/ollama</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Run-a-model\"><a href=\"#Run-a-model\" class=\"headerlink\" title=\"Run a model\"></a>Run a model</h3><p>Now you can run a model like Llama 2 inside the container.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">exec</span> -it ollama ollama run llama2-chinese</span><br></pre></td></tr></table></figure>\n\n\n\n<p>用上一次的webui 关联起来就是</p>\n<p>给ollama弄一个前端UI</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">open-webui:</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8107</span><span class=\"string\">:8080</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">11434</span><span class=\"string\">:11434</span></span><br><span class=\"line\">        <span class=\"attr\">extra_hosts:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">host.docker.internal:host-gateway</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">./open-webui-data:/app/backend/data</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">/root/ollama/ollama:/root/.ollama</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">open-webui</span></span><br><span class=\"line\">        <span class=\"attr\">restart:</span> <span class=\"string\">always</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">ghcr.io/open-webui/open-webui:main</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>        - /root/ollama/ollama:/root/.ollama \n        - 尝试关联本机中的ollama(独立运行的)\n        - \n</code></pre>\n<p><a href=\"https://www.runoob.com/ollama/ollama-open-webui.html\">https://www.runoob.com/ollama/ollama-open-webui.html</a></p>\n<h2 id=\"TTS\"><a href=\"#TTS\" class=\"headerlink\" title=\"TTS\"></a>TTS</h2><p><a href=\"https://www.youtube.com/watch?v=r8r1VFbhh1w\">Coqui TTS Setup via Docker: Voice AI on Linux Mint</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu</span><br><span class=\"line\"></span><br><span class=\"line\">python3 TTS/server/server.py --model_name tts_models/en/vctk/vits</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">ollama:</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">./ollama:/root/.ollama</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8106</span><span class=\"string\">:11434</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">ollama</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">ollama/ollama</span></span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://192.168.6.117:8106/\">http://192.168.6.117:8106/</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Ollama is running</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Run-a-model-1\"><a href=\"#Run-a-model-1\" class=\"headerlink\" title=\"Run a model\"></a>Run a model</h3><p>Now you can run a model like Llama 2 inside the container.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">exec</span> -it ollama ollama run ChatTTS-Ollama</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>StyleTTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFV0VE5VbnJvX1k3cWhCdmFPZk1qcWZJWVlpUXxBQ3Jtc0tucEU0OUM1YXRjOXVDQS1MNlRWOTQ5RE5md2NNR0pvNExMdGcyblJBWGgwMks4ZU9LOEdLdUo2MnUyUVZTdlVYUl83VFl5Qm43anpOaF9XSmpHbjQtNkxDTF9Xd1haZ0l5SU9CWGl5TFk1ZkR5dzk3cw&q=https://github.com/yl4579/StyleTTS2?tab=readme-ov-file&v=lPitjhhodaw\">https://github.com/yl4579/StyleTTS2?t...</a> Eleven’s Style TTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVBhS01WTlI2eFNWZ1lhajh3eWxQLUVSQ083Z3xBQ3Jtc0trWnYyVV8zOExUaGExNUVXX2ZmNjcxT3pqMm5FdzVMbXlmR1dvXzVkZDJtLXRqTVdZQUJyWHlaVGd3ZlhwRndfOVdEOTVRVlE5Vjc2SnltV1JqdnVFMUZyazhkV3N0X1dhdWdqSzJ2Y3Y2OXk1bklaSQ&q=https://github.com/IIEleven11/StyleTTS2FineTune&v=lPitjhhodaw\">https://github.com/IIEleven11/StyleTT...</a> </p>\n<p>Coqui TTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbllvV1M0U3duWF9teUpBUWE3LVJmUW5rbFlwQXxBQ3Jtc0tud3hOSXlLMUo3Vk9mYzI0YkY5N3pLNnVtSF9lZlJ5UDUzanc5akNmb3hrcnh0YmVzbmdCZl9aSklydGVPUjEzdm40ekVlbU1IWWhXU2o5bWNwN2x2Y2tad2NhdldJUjVyNDluSFp4XzhrTzJJcURQNA&q=https://github.com/coqui-ai/TTS&v=lPitjhhodaw\">https://github.com/coqui-ai/TTS</a> </p>\n<p>Daswers XTTS GUI - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa296V1ZRQnVCNkdUSDNSN1Z5cTFNdk5ZLWthQXxBQ3Jtc0tsXzNGczhVa1hYTTR2ZC0yLWhvZ1ZZVl9PX3JHM1p1Zm5IdU4zcW52V0E1QVJHem4xZzhuQW5fVGgxTExtXzNaYmRBOGRCQlZRamEwRk9mdmxYbFZfUnRCZ1lTUXEwam05UEFaaGpuT2hydkdLRkhnOA&q=https://github.com/daswer123/xtts-finetune-webui&v=lPitjhhodaw\">https://github.com/daswer123/xtts-fin...</a> </p>\n<p>Suno Bark - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2stNnpaWXlNcjhJLW5rWTNkOU1RbllQaE1kZ3xBQ3Jtc0tuYWpQSUc5dER6cFB6WVd3MUE0SXJlenNHNWZHdURuWVI1SmFkQUlsNUM0ak5kbFNHX0F5ekwySVE2d21FZGFscmc1M3Jlcm9ORjlOazhHM3A3QmN6QlYxdi1OTHFHUVpWZ1hLaWlYUm5zclBReUY0aw&q=https://github.com/suno-ai/bark&v=lPitjhhodaw\">https://github.com/suno-ai/bark</a><br>VallE-X - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbEJjSTlsWjREOER0R0FxZWVOTW0xeXhacWJJQXxBQ3Jtc0trUndvNFQ4LUkySzdnZzlHUHQ1WU9EbUdTTy1WRVJlREdMc0R5TmI0LXlncTJNeWdwRTNudGZialYwRDc1cDFHbS1wYk8tVEg3WXJkMDRvSjJGSWxCZnVYdDVpRzllXzcxSUNQRnU0Z28zc3I1UEdWRQ&q=https://github.com/Plachtaa/VALL-E-X&v=lPitjhhodaw\">https://github.com/Plachtaa/VALL-E-X</a> </p>\n<p><del>Tortoise TTS Installation - <a href=\"https://www.youtube.com/watch?v=p31Ax_A5VKA&pp=0gcJCR0AztywvtLA\"> <img data-src=\"https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png\" alt=\"img\"> • Local AI Voice Cloning with Tortoise TTS -…  </a></del> NVIDIA GPUs</p>\n<p>最终的成功案例: </p>\n<p><a href=\"https://github.com/jianchang512/ChatTTS-ui/tree/main\">https://github.com/jianchang512/ChatTTS-ui/tree/main</a></p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><ol>\n<li><p>拉取项目仓库</p>\n<p>在任意路径下克隆项目，例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/jianchang512/ChatTTS-ui.git chat-tts-ui</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>启动 Runner</p>\n<p>进入到项目目录：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd chat-tts-ui</span><br></pre></td></tr></table></figure>\n\n\n\n<p>启动容器并查看初始化日志：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gpu版本</span><br><span class=\"line\">docker compose -f docker-compose.gpu.yaml up -d </span><br><span class=\"line\"></span><br><span class=\"line\">cpu版本    </span><br><span class=\"line\">docker compose -f docker-compose.cpu.yaml up -d</span><br><span class=\"line\"></span><br><span class=\"line\">docker compose logs -f --no-log-prefix</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>访问 ChatTTS WebUI</p>\n<p><code>启动:[&#39;0.0.0.0&#39;, &#39;9966&#39;]</code>，也即，访问部署设备的 <code>IP:9966</code> 即可，例如：</p>\n<ul>\n<li>本机：<code>http://127.0.0.1:9966</code></li>\n<li>服务器: <code>http://192.168.1.100:9966</code></li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Attaching to chat-tts-ui                                                                                        </span><br><span class=\"line\">chat-tts-ui  | Starting...                                                                                      </span><br><span class=\"line\">chat-tts-ui  | Traceback (most recent call last):                                                               </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/app.py&quot;, line 24, in                                                        </span><br><span class=\"line\">chat-tts-ui  |     import ChatTTS                                                                               </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/__init__.py&quot;, line 1, in                                            </span><br><span class=\"line\">chat-tts-ui  |     from .core import Chat                                                                       </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/core.py&quot;, line 18, in                                               </span><br><span class=\"line\">chat-tts-ui  |     from .model import DVAE, GPT, gen_logits, Tokenizer                                          </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/__init__.py&quot;, line 4, in                                      </span><br><span class=\"line\">chat-tts-ui  |     from .tokenizer import Tokenizer                                                             </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/tokenizer.py&quot;, line 20, in                                    </span><br><span class=\"line\">chat-tts-ui  |     class Tokenizer:                                                                             </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/tokenizer.py&quot;, line 22, in Tokenizer                                  </span><br><span class=\"line\">chat-tts-ui  |     self, tokenizer_path: torch.serialization.FILE_LIKE, device: torch.device                    </span><br><span class=\"line\">chat-tts-ui  | AttributeError: module &#x27;torch.serialization&#x27; has no attribute &#x27;FILE_LIKE&#x27;                        </span><br><span class=\"line\">chat-tts-ui exited with code 1                                                                                  </span><br><span class=\"line\">chat-tts-ui  | Starting...                                                                                      </span><br><span class=\"line\">  Gracefully stopping... (press Ctrl+C again to force)                                                          </span><br><span class=\"line\">[+] Stopping 1/1                                                                                                </span><br><span class=\"line\"> ✔ Container chat-tts-ui  Stopped</span><br></pre></td></tr></table></figure>\n\n<p>解决办法: <a href=\"https://github.com/2noise/ChatTTS/issues/933\">https://github.com/2noise/ChatTTS/issues/933</a></p>\n<p>修改requirements.txt 中的 torch&#x3D;&#x3D;2.1.0 </p>\n<p>用法1: <a href=\"https://tts1.carlzeng.com:3/\">https://tts1.carlzeng.com:3/</a></p>\n<p>用法2: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># API调用代码</span><br><span class=\"line\"></span><br><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">res = requests.post(&#x27;https://tts1.carlzeng.com:3/tts&#x27;, data=&#123;</span><br><span class=\"line\">  &quot;text&quot;: &quot;若不懂无需填写&quot;,</span><br><span class=\"line\">  &quot;prompt&quot;: &quot;&quot;,</span><br><span class=\"line\">  &quot;voice&quot;: &quot;3333&quot;,</span><br><span class=\"line\">  &quot;temperature&quot;: 0.3,</span><br><span class=\"line\">  &quot;top_p&quot;: 0.7,</span><br><span class=\"line\">  &quot;top_k&quot;: 20,</span><br><span class=\"line\">  &quot;skip_refine&quot;: 0,</span><br><span class=\"line\">  &quot;custom_voice&quot;: 0</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">print(res.json())</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"收藏图片-logo在线编辑工具\"><a href=\"#收藏图片-logo在线编辑工具\" class=\"headerlink\" title=\"收藏图片&#x2F;logo在线编辑工具\"></a>收藏图片&#x2F;logo在线编辑工具</h2><p>把SVG压缩以后,背景就消失了<br>    <a href=\"https://www.iloveimg.com/zh-cn/download/hvprdj3nv68q7vbb5j2b304x3kfkj4g0c5by0207q39vxwg0pjjdp188dy2vn2rlj0986Ab0wkfcb7rty217p5hk9nmAqtvhtpn2m43ln4btdhqpw6vhrfskftn04g4zzkfv6wg3w5n13hx6qwdyg6pvylnkqpgtgcAs2z467t0tjwtb0g2q/12\">https://www.iloveimg.com/zh-cn/download/hvprdj3nv68q7vbb5j2b304x3kfkj4g0c5by0207q39vxwg0pjjdp188dy2vn2rlj0986Ab0wkfcb7rty217p5hk9nmAqtvhtpn2m43ln4btdhqpw6vhrfskftn04g4zzkfv6wg3w5n13hx6qwdyg6pvylnkqpgtgcAs2z467t0tjwtb0g2q/12</a></p>\n<pre><code>结果: \n&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;180&quot; height=&quot;180&quot;&gt;&lt;path fill=&quot;#94334B&quot; d=&quot;M111 72c-.01.816-.02 1.631-.032 2.472q-.051 4.629-.078 9.259c-.015 1.969-.04 3.937-.066 5.906-.081 16.044 2.86 30.22 9.969 44.613C122 137 122 137 122 140c-11.961.095-23.923.182-35.875-.375l-2.372-.094c-3.718-.2-5.588-.421-8.753-2.531l-3.437-.687c-15.817-3.868-27.508-17.323-35.849-30.555C30.363 96.917 29.838 89.128 30 79l3.875.813C41.878 81.42 49.945 82.683 58 84v2c4.479.117 8.957.188 13.438.25l3.818.102C82.813 86.43 88.432 85.832 95 82l2.75-1.437c2.421-1.577 2.421-1.577 4.75-4.126C104.908 74.09 107.445 72 111 72&quot;/&gt;&lt;path fill=&quot;#95354D&quot; d=&quot;M115 69c3.666-.147 7.332-.234 11-.312l3.121-.127c8.516-.136 12.948 1.984 19.234 7.51 9.312 10.442 12.457 21.242 11.824 34.969-.7 7.651-5.041 14.439-10.179 19.96-6.524 5.165-11.967 6.099-20 6-15.184-26.364-15.184-26.364-15.098-39.484l.005-2.472c.005-2.598.018-5.196.03-7.794q.009-2.646.014-5.293.017-6.478.049-12.957m14 10c-.417 2.5-.417 2.5 0 5 2.77 2.315 2.77 2.315 5.625 1.688 2.31-.462 2.31-.462 3.375-1.688.25-2.458.25-2.458 0-5-1.827-2.25-1.827-2.25-4.5-2.25s-2.673 0-4.5 2.25&quot;/&gt;&lt;path fill=&quot;#AF9E5A&quot; d=&quot;M113 72h1l.044 2.488q.094 4.65.218 9.298c.05 1.98.084 3.959.119 5.939.318 11.425 2.523 20.805 7.557 31.025l1.013 2.129c2.162 4.49 4.39 8.903 7.049 13.121 2.621 1.045 2.621 1.045 5 1a149 149 0 0 1-5.383 3.445c-4.628 2.835-8.78 5.578-12.617 9.43-6.724 6.272-15.674 9.486-24 13.125l-2.038.927C88.115 165.204 86.16 166 83 166l-.563-2.447a1226 1226 0 0 0-2.624-10.928l-.885-3.852-.908-3.671-.81-3.396c-.975-2.927-.975-2.927-3.836-4.087L71 137c1.813-.625 1.813-.625 4-1l3 2c2.076.363 2.076.363 4.38.41l2.668.122 2.87.1 2.947.127c3.107.13 6.215.248 9.323.366q3.159.13 6.318.262 7.746.32 15.494.613l-1.251-3.105-1.64-4.083-.822-2.04c-1.954-4.869-3.748-9.755-5.287-14.772l-1.125-3.562c-1.713-6.73-2.07-13.403-2.062-20.313v-2.377c.144-14.705.144-14.705 3.187-17.748&quot;/&gt;&lt;path fill=&quot;#B2A35E&quot; d=&quot;M19 50c11.074 0 11.074 0 15 2 5.35 7.817 9 20.6 9 30q-2.407-.466-4.812-.937l-2.708-.528C33 80 33 80 30 79l2 18-25-1C1 83.25 1 83.25 1 81q4.185-1.505 8.375-3l2.406-.867 2.305-.82 2.126-.762C18 75 18 75 20 75z&quot;/&gt;&lt;path fill=&quot;#B0A25C&quot; d=&quot;M60 62c4.594.599 8.45 1.834 12.719 3.617l1.881.781q1.959.816 3.913 1.64c1.979.834 3.961 1.658 5.944 2.482C90.059 72.857 95.592 75.234 101 78c-3.559 4.333-7.957 5.926-13 8l-2 1c-2.844.1-5.657.141-8.5.125l-2.457-.006C69.305 87.078 63.696 86.735 58 86l3-1-.496-1.918c-.679-4.15-.61-8.198-.566-12.394l.013-2.534q.02-3.077.049-6.154&quot;/&gt;&lt;path fill=&quot;#B48179&quot; d=&quot;m123.938 67.688 2.65.068c2.138.058 4.275.148 6.412.244v1h-18v32h-1l-1-28-1 6h-1l-1-6h-3c5.724-4.932 9.497-5.68 16.938-5.312&quot;/&gt;&lt;path fill=&quot;#AA9450&quot; d=&quot;M133.5 76.75C136 77 136 77 138 79c.313 2.5.313 2.5 0 5-3 2-3 2-5.625 1.688C130 85 130 85 129 84c-.187-2.437-.187-2.437 0-5 2-2 2-2 4.5-2.25&quot;/&gt;&lt;/svg&gt;\n\n\nBgRemover - 在线图片去底工具 - 将纯色背景的图片转换为背景透明的图片\nhttps://www.aigei.com/bgremover/\n\n转化为SVG\nhttps://www.freeconvert.com/\n</code></pre>\n<h1 id=\"灵感来源\"><a href=\"#灵感来源\" class=\"headerlink\" title=\"灵感来源\"></a>灵感来源</h1><p><a href=\"https://cloud.tencent.com.cn/developer/article/2406985?areaId=106001\">群晖NAS使用Docker部署大语言模型Llama 2结合内网穿透实现公网访问本地GPT聊天服务</a></p>\n<p>docker 部署 Liama</p>\n<p><a href=\"https://github.com/LlamaFamily/Llama-Chinese\">https://github.com/LlamaFamily/Llama-Chinese</a></p>\n","more":"<div> \n<button onclick=\"synthesizeSpeech()\">朗读全文</button>\n</div>\n<audio controls id=\"audioPlayer\">Your browser does not support the audio element.</audio>      \n<script>\n  function synthesizeSpeech() { \n    var inputText = document.getElementsByClassName('post-block')[0].innerText;\n    var voice = \"ZH\";\n    var url = 'https://tts.carlzeng.com:3/speech?text=' + encodeURIComponent(inputText.substring(0,3000)) + '&voice=' + voice;\n    var audioPlayer = document.getElementById('audioPlayer');          \n    audioPlayer.src = url;\n    audioPlayer.load();\n    audioPlayer.play();\n  }\n</script>\n\n\n\n\n<h1 id=\"有什么用\"><a href=\"#有什么用\" class=\"headerlink\" title=\"有什么用\"></a>有什么用</h1><p>体验一下AI目前在CPU上运行的应用; 用来学习AI大语言模型</p>\n<p>本文被停滞了将近1年半时间; 受制于硬件和时间关系; 即便最近跑通了也更尴尬. 只要一请求打一点的运算, CPU马上100%占用. 下一步: 安排英伟达的GPU登场</p>\n<h1 id=\"怎么用\"><a href=\"#怎么用\" class=\"headerlink\" title=\"怎么用\"></a>怎么用</h1><h2 id=\"拉取Ollama镜像命令\"><a href=\"#拉取Ollama镜像命令\" class=\"headerlink\" title=\"*拉取Ollama镜像命令\"></a>*拉取Ollama镜像命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker  pull ollama/ollama:latest</span><br></pre></td></tr></table></figure>\n\n<p>然后在bash命令界面,执行<code>ollama run llama2</code>命令，接着等待下载即可,最后出现success,表示下载运行Llama 2模型成功</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -it ollama-ollama1 bash    </span><br><span class=\"line\">root@ollama-ollama1:/# ollama run llama2                                                                  </span><br><span class=\"line\">pulling manifest                                                                                          </span><br><span class=\"line\">pulling 8934d96d3f08...  89% ▕█████████████████████████████████████     ▏ 3.4 GB/3.8 GB  4.8 MB/s   1m26s</span><br></pre></td></tr></table></figure>\n\n<p>教程：<a href=\"https://github.com/ollama/ollama\">https://github.com/ollama/ollama</a></p>\n<p>Remove a model<br>    ollama rm llama2</p>\n<p>卡死；删除整个container，空间没有得到释放，郁闷。。。</p>\n<p>20240423放弃，因为对CPU的占用太大。</p>\n<h2 id=\"拉取Chatbot-Ollama（这是UI）镜像命令\"><a href=\"#拉取Chatbot-Ollama（这是UI）镜像命令\" class=\"headerlink\" title=\"*拉取Chatbot-Ollama（这是UI）镜像命令\"></a>*拉取Chatbot-Ollama（这是UI）镜像命令</h2><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo docker  pull ghcr.io/ivanfioravanti/chatbot-ollama:main</span><br></pre></td></tr></table></figure>\n\n<p>然后设置这个UI的一个变量：该变量就是连接我们上面运行Ollama框架服务的地址,我们设置本地地址:</p>\n<p>http:&#x2F;&#x2F;群晖局域网IP:11434</p>\n<h1 id=\"相关内容\"><a href=\"#相关内容\" class=\"headerlink\" title=\"相关内容\"></a>相关内容</h1><iframe style=\"box-shadow: 0px 0px 20px -10px;\" src=\"https://query.carlzeng.com:3/appsearch?q=ai\" frameborder=\"0\" scrolling=\"auto\" width=\"100%\" height=\"500\"></iframe>\n\n<h1 id=\"实现方法\"><a href=\"#实现方法\" class=\"headerlink\" title=\"实现方法\"></a>实现方法</h1><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">localai:</span></span><br><span class=\"line\">        <span class=\"attr\">tty:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">stdin_open:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">local-ai</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8105</span><span class=\"string\">:8080</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">localai/localai:latest-aio-cpu</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">~/models:/models:cached</span></span><br></pre></td></tr></table></figure>\n\n<p>运行之前: </p>\n<p><img data-src=\"https://img.carlzeng.com:3/i/2025/11/21/6920195f995a9.png\" alt=\"image-20251121154835867\"></p>\n<p>运行之后: </p>\n<p><img data-src=\"https://img.carlzeng.com:3/i/2025/11/21/692046c34be1e.png\" alt=\"image-20251121190221555\"></p>\n<p>可见CPU直接飙满了~. 还好当没有请求的时候cpu不是一直这样保持爆满的状态</p>\n<p>curl <a href=\"http://192.168.6.117:8105/tts\">http://192.168.6.117:8105/tts</a> -H “Content-Type: application&#x2F;json” -d ‘{<br>  “input”: “Hello world”,<br>  “model”: “tts”<br>}’</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Load model from /models/tts failed:Load model /models/tts failed. File doesn&#x27;t exist&quot;</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"CPU-only\"><a href=\"#CPU-only\" class=\"headerlink\" title=\"CPU only\"></a>CPU only</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">version: &quot;3&quot;</span><br><span class=\"line\">services:</span><br><span class=\"line\">    ollama:</span><br><span class=\"line\">        volumes:</span><br><span class=\"line\">            - ./ollama:/root/.ollama</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">            - 8106:11434</span><br><span class=\"line\">        container_name: ollama</span><br><span class=\"line\">        image: ollama/ollama</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Run-a-model\"><a href=\"#Run-a-model\" class=\"headerlink\" title=\"Run a model\"></a>Run a model</h3><p>Now you can run a model like Llama 2 inside the container.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">exec</span> -it ollama ollama run llama2-chinese</span><br></pre></td></tr></table></figure>\n\n\n\n<p>用上一次的webui 关联起来就是</p>\n<p>给ollama弄一个前端UI</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">open-webui:</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8107</span><span class=\"string\">:8080</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">11434</span><span class=\"string\">:11434</span></span><br><span class=\"line\">        <span class=\"attr\">extra_hosts:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">host.docker.internal:host-gateway</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">./open-webui-data:/app/backend/data</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">/root/ollama/ollama:/root/.ollama</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">open-webui</span></span><br><span class=\"line\">        <span class=\"attr\">restart:</span> <span class=\"string\">always</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">ghcr.io/open-webui/open-webui:main</span></span><br></pre></td></tr></table></figure>\n\n<pre><code>        - /root/ollama/ollama:/root/.ollama \n        - 尝试关联本机中的ollama(独立运行的)\n        - \n</code></pre>\n<p><a href=\"https://www.runoob.com/ollama/ollama-open-webui.html\">https://www.runoob.com/ollama/ollama-open-webui.html</a></p>\n<h2 id=\"TTS\"><a href=\"#TTS\" class=\"headerlink\" title=\"TTS\"></a>TTS</h2><p><a href=\"https://www.youtube.com/watch?v=r8r1VFbhh1w\">Coqui TTS Setup via Docker: Voice AI on Linux Mint</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu</span><br><span class=\"line\"></span><br><span class=\"line\">python3 TTS/server/server.py --model_name tts_models/en/vctk/vits</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">&quot;3&quot;</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">    <span class=\"attr\">ollama:</span></span><br><span class=\"line\">        <span class=\"attr\">volumes:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"string\">./ollama:/root/.ollama</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">            <span class=\"bullet\">-</span> <span class=\"number\">8106</span><span class=\"string\">:11434</span></span><br><span class=\"line\">        <span class=\"attr\">container_name:</span> <span class=\"string\">ollama</span></span><br><span class=\"line\">        <span class=\"attr\">image:</span> <span class=\"string\">ollama/ollama</span></span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://192.168.6.117:8106/\">http://192.168.6.117:8106/</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Ollama is running</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Run-a-model-1\"><a href=\"#Run-a-model-1\" class=\"headerlink\" title=\"Run a model\"></a>Run a model</h3><p>Now you can run a model like Llama 2 inside the container.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker <span class=\"built_in\">exec</span> -it ollama ollama run ChatTTS-Ollama</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>StyleTTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFV0VE5VbnJvX1k3cWhCdmFPZk1qcWZJWVlpUXxBQ3Jtc0tucEU0OUM1YXRjOXVDQS1MNlRWOTQ5RE5md2NNR0pvNExMdGcyblJBWGgwMks4ZU9LOEdLdUo2MnUyUVZTdlVYUl83VFl5Qm43anpOaF9XSmpHbjQtNkxDTF9Xd1haZ0l5SU9CWGl5TFk1ZkR5dzk3cw&q=https://github.com/yl4579/StyleTTS2?tab=readme-ov-file&v=lPitjhhodaw\">https://github.com/yl4579/StyleTTS2?t...</a> Eleven’s Style TTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVBhS01WTlI2eFNWZ1lhajh3eWxQLUVSQ083Z3xBQ3Jtc0trWnYyVV8zOExUaGExNUVXX2ZmNjcxT3pqMm5FdzVMbXlmR1dvXzVkZDJtLXRqTVdZQUJyWHlaVGd3ZlhwRndfOVdEOTVRVlE5Vjc2SnltV1JqdnVFMUZyazhkV3N0X1dhdWdqSzJ2Y3Y2OXk1bklaSQ&q=https://github.com/IIEleven11/StyleTTS2FineTune&v=lPitjhhodaw\">https://github.com/IIEleven11/StyleTT...</a> </p>\n<p>Coqui TTS - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbllvV1M0U3duWF9teUpBUWE3LVJmUW5rbFlwQXxBQ3Jtc0tud3hOSXlLMUo3Vk9mYzI0YkY5N3pLNnVtSF9lZlJ5UDUzanc5akNmb3hrcnh0YmVzbmdCZl9aSklydGVPUjEzdm40ekVlbU1IWWhXU2o5bWNwN2x2Y2tad2NhdldJUjVyNDluSFp4XzhrTzJJcURQNA&q=https://github.com/coqui-ai/TTS&v=lPitjhhodaw\">https://github.com/coqui-ai/TTS</a> </p>\n<p>Daswers XTTS GUI - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa296V1ZRQnVCNkdUSDNSN1Z5cTFNdk5ZLWthQXxBQ3Jtc0tsXzNGczhVa1hYTTR2ZC0yLWhvZ1ZZVl9PX3JHM1p1Zm5IdU4zcW52V0E1QVJHem4xZzhuQW5fVGgxTExtXzNaYmRBOGRCQlZRamEwRk9mdmxYbFZfUnRCZ1lTUXEwam05UEFaaGpuT2hydkdLRkhnOA&q=https://github.com/daswer123/xtts-finetune-webui&v=lPitjhhodaw\">https://github.com/daswer123/xtts-fin...</a> </p>\n<p>Suno Bark - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2stNnpaWXlNcjhJLW5rWTNkOU1RbllQaE1kZ3xBQ3Jtc0tuYWpQSUc5dER6cFB6WVd3MUE0SXJlenNHNWZHdURuWVI1SmFkQUlsNUM0ak5kbFNHX0F5ekwySVE2d21FZGFscmc1M3Jlcm9ORjlOazhHM3A3QmN6QlYxdi1OTHFHUVpWZ1hLaWlYUm5zclBReUY0aw&q=https://github.com/suno-ai/bark&v=lPitjhhodaw\">https://github.com/suno-ai/bark</a><br>VallE-X - <a href=\"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbEJjSTlsWjREOER0R0FxZWVOTW0xeXhacWJJQXxBQ3Jtc0trUndvNFQ4LUkySzdnZzlHUHQ1WU9EbUdTTy1WRVJlREdMc0R5TmI0LXlncTJNeWdwRTNudGZialYwRDc1cDFHbS1wYk8tVEg3WXJkMDRvSjJGSWxCZnVYdDVpRzllXzcxSUNQRnU0Z28zc3I1UEdWRQ&q=https://github.com/Plachtaa/VALL-E-X&v=lPitjhhodaw\">https://github.com/Plachtaa/VALL-E-X</a> </p>\n<p><del>Tortoise TTS Installation - <a href=\"https://www.youtube.com/watch?v=p31Ax_A5VKA&pp=0gcJCR0AztywvtLA\"> <img data-src=\"https://www.gstatic.com/youtube/img/watch/yt_favicon_ringo2.png\" alt=\"img\"> • Local AI Voice Cloning with Tortoise TTS -…  </a></del> NVIDIA GPUs</p>\n<p>最终的成功案例: </p>\n<p><a href=\"https://github.com/jianchang512/ChatTTS-ui/tree/main\">https://github.com/jianchang512/ChatTTS-ui/tree/main</a></p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><ol>\n<li><p>拉取项目仓库</p>\n<p>在任意路径下克隆项目，例如：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/jianchang512/ChatTTS-ui.git chat-tts-ui</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>启动 Runner</p>\n<p>进入到项目目录：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd chat-tts-ui</span><br></pre></td></tr></table></figure>\n\n\n\n<p>启动容器并查看初始化日志：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gpu版本</span><br><span class=\"line\">docker compose -f docker-compose.gpu.yaml up -d </span><br><span class=\"line\"></span><br><span class=\"line\">cpu版本    </span><br><span class=\"line\">docker compose -f docker-compose.cpu.yaml up -d</span><br><span class=\"line\"></span><br><span class=\"line\">docker compose logs -f --no-log-prefix</span><br></pre></td></tr></table></figure>\n\n\n</li>\n<li><p>访问 ChatTTS WebUI</p>\n<p><code>启动:[&#39;0.0.0.0&#39;, &#39;9966&#39;]</code>，也即，访问部署设备的 <code>IP:9966</code> 即可，例如：</p>\n<ul>\n<li>本机：<code>http://127.0.0.1:9966</code></li>\n<li>服务器: <code>http://192.168.1.100:9966</code></li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Attaching to chat-tts-ui                                                                                        </span><br><span class=\"line\">chat-tts-ui  | Starting...                                                                                      </span><br><span class=\"line\">chat-tts-ui  | Traceback (most recent call last):                                                               </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/app.py&quot;, line 24, in                                                        </span><br><span class=\"line\">chat-tts-ui  |     import ChatTTS                                                                               </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/__init__.py&quot;, line 1, in                                            </span><br><span class=\"line\">chat-tts-ui  |     from .core import Chat                                                                       </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/core.py&quot;, line 18, in                                               </span><br><span class=\"line\">chat-tts-ui  |     from .model import DVAE, GPT, gen_logits, Tokenizer                                          </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/__init__.py&quot;, line 4, in                                      </span><br><span class=\"line\">chat-tts-ui  |     from .tokenizer import Tokenizer                                                             </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/tokenizer.py&quot;, line 20, in                                    </span><br><span class=\"line\">chat-tts-ui  |     class Tokenizer:                                                                             </span><br><span class=\"line\">chat-tts-ui  |   File &quot;/app/ChatTTS/model/tokenizer.py&quot;, line 22, in Tokenizer                                  </span><br><span class=\"line\">chat-tts-ui  |     self, tokenizer_path: torch.serialization.FILE_LIKE, device: torch.device                    </span><br><span class=\"line\">chat-tts-ui  | AttributeError: module &#x27;torch.serialization&#x27; has no attribute &#x27;FILE_LIKE&#x27;                        </span><br><span class=\"line\">chat-tts-ui exited with code 1                                                                                  </span><br><span class=\"line\">chat-tts-ui  | Starting...                                                                                      </span><br><span class=\"line\">  Gracefully stopping... (press Ctrl+C again to force)                                                          </span><br><span class=\"line\">[+] Stopping 1/1                                                                                                </span><br><span class=\"line\"> ✔ Container chat-tts-ui  Stopped</span><br></pre></td></tr></table></figure>\n\n<p>解决办法: <a href=\"https://github.com/2noise/ChatTTS/issues/933\">https://github.com/2noise/ChatTTS/issues/933</a></p>\n<p>修改requirements.txt 中的 torch&#x3D;&#x3D;2.1.0 </p>\n<p>用法1: <a href=\"https://tts1.carlzeng.com:3/\">https://tts1.carlzeng.com:3/</a></p>\n<p>用法2: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># API调用代码</span><br><span class=\"line\"></span><br><span class=\"line\">import requests</span><br><span class=\"line\"></span><br><span class=\"line\">res = requests.post(&#x27;https://tts1.carlzeng.com:3/tts&#x27;, data=&#123;</span><br><span class=\"line\">  &quot;text&quot;: &quot;若不懂无需填写&quot;,</span><br><span class=\"line\">  &quot;prompt&quot;: &quot;&quot;,</span><br><span class=\"line\">  &quot;voice&quot;: &quot;3333&quot;,</span><br><span class=\"line\">  &quot;temperature&quot;: 0.3,</span><br><span class=\"line\">  &quot;top_p&quot;: 0.7,</span><br><span class=\"line\">  &quot;top_k&quot;: 20,</span><br><span class=\"line\">  &quot;skip_refine&quot;: 0,</span><br><span class=\"line\">  &quot;custom_voice&quot;: 0</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">print(res.json())</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"收藏图片-logo在线编辑工具\"><a href=\"#收藏图片-logo在线编辑工具\" class=\"headerlink\" title=\"收藏图片&#x2F;logo在线编辑工具\"></a>收藏图片&#x2F;logo在线编辑工具</h2><p>把SVG压缩以后,背景就消失了<br>    <a href=\"https://www.iloveimg.com/zh-cn/download/hvprdj3nv68q7vbb5j2b304x3kfkj4g0c5by0207q39vxwg0pjjdp188dy2vn2rlj0986Ab0wkfcb7rty217p5hk9nmAqtvhtpn2m43ln4btdhqpw6vhrfskftn04g4zzkfv6wg3w5n13hx6qwdyg6pvylnkqpgtgcAs2z467t0tjwtb0g2q/12\">https://www.iloveimg.com/zh-cn/download/hvprdj3nv68q7vbb5j2b304x3kfkj4g0c5by0207q39vxwg0pjjdp188dy2vn2rlj0986Ab0wkfcb7rty217p5hk9nmAqtvhtpn2m43ln4btdhqpw6vhrfskftn04g4zzkfv6wg3w5n13hx6qwdyg6pvylnkqpgtgcAs2z467t0tjwtb0g2q/12</a></p>\n<pre><code>结果: \n&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;180&quot; height=&quot;180&quot;&gt;&lt;path fill=&quot;#94334B&quot; d=&quot;M111 72c-.01.816-.02 1.631-.032 2.472q-.051 4.629-.078 9.259c-.015 1.969-.04 3.937-.066 5.906-.081 16.044 2.86 30.22 9.969 44.613C122 137 122 137 122 140c-11.961.095-23.923.182-35.875-.375l-2.372-.094c-3.718-.2-5.588-.421-8.753-2.531l-3.437-.687c-15.817-3.868-27.508-17.323-35.849-30.555C30.363 96.917 29.838 89.128 30 79l3.875.813C41.878 81.42 49.945 82.683 58 84v2c4.479.117 8.957.188 13.438.25l3.818.102C82.813 86.43 88.432 85.832 95 82l2.75-1.437c2.421-1.577 2.421-1.577 4.75-4.126C104.908 74.09 107.445 72 111 72&quot;/&gt;&lt;path fill=&quot;#95354D&quot; d=&quot;M115 69c3.666-.147 7.332-.234 11-.312l3.121-.127c8.516-.136 12.948 1.984 19.234 7.51 9.312 10.442 12.457 21.242 11.824 34.969-.7 7.651-5.041 14.439-10.179 19.96-6.524 5.165-11.967 6.099-20 6-15.184-26.364-15.184-26.364-15.098-39.484l.005-2.472c.005-2.598.018-5.196.03-7.794q.009-2.646.014-5.293.017-6.478.049-12.957m14 10c-.417 2.5-.417 2.5 0 5 2.77 2.315 2.77 2.315 5.625 1.688 2.31-.462 2.31-.462 3.375-1.688.25-2.458.25-2.458 0-5-1.827-2.25-1.827-2.25-4.5-2.25s-2.673 0-4.5 2.25&quot;/&gt;&lt;path fill=&quot;#AF9E5A&quot; d=&quot;M113 72h1l.044 2.488q.094 4.65.218 9.298c.05 1.98.084 3.959.119 5.939.318 11.425 2.523 20.805 7.557 31.025l1.013 2.129c2.162 4.49 4.39 8.903 7.049 13.121 2.621 1.045 2.621 1.045 5 1a149 149 0 0 1-5.383 3.445c-4.628 2.835-8.78 5.578-12.617 9.43-6.724 6.272-15.674 9.486-24 13.125l-2.038.927C88.115 165.204 86.16 166 83 166l-.563-2.447a1226 1226 0 0 0-2.624-10.928l-.885-3.852-.908-3.671-.81-3.396c-.975-2.927-.975-2.927-3.836-4.087L71 137c1.813-.625 1.813-.625 4-1l3 2c2.076.363 2.076.363 4.38.41l2.668.122 2.87.1 2.947.127c3.107.13 6.215.248 9.323.366q3.159.13 6.318.262 7.746.32 15.494.613l-1.251-3.105-1.64-4.083-.822-2.04c-1.954-4.869-3.748-9.755-5.287-14.772l-1.125-3.562c-1.713-6.73-2.07-13.403-2.062-20.313v-2.377c.144-14.705.144-14.705 3.187-17.748&quot;/&gt;&lt;path fill=&quot;#B2A35E&quot; d=&quot;M19 50c11.074 0 11.074 0 15 2 5.35 7.817 9 20.6 9 30q-2.407-.466-4.812-.937l-2.708-.528C33 80 33 80 30 79l2 18-25-1C1 83.25 1 83.25 1 81q4.185-1.505 8.375-3l2.406-.867 2.305-.82 2.126-.762C18 75 18 75 20 75z&quot;/&gt;&lt;path fill=&quot;#B0A25C&quot; d=&quot;M60 62c4.594.599 8.45 1.834 12.719 3.617l1.881.781q1.959.816 3.913 1.64c1.979.834 3.961 1.658 5.944 2.482C90.059 72.857 95.592 75.234 101 78c-3.559 4.333-7.957 5.926-13 8l-2 1c-2.844.1-5.657.141-8.5.125l-2.457-.006C69.305 87.078 63.696 86.735 58 86l3-1-.496-1.918c-.679-4.15-.61-8.198-.566-12.394l.013-2.534q.02-3.077.049-6.154&quot;/&gt;&lt;path fill=&quot;#B48179&quot; d=&quot;m123.938 67.688 2.65.068c2.138.058 4.275.148 6.412.244v1h-18v32h-1l-1-28-1 6h-1l-1-6h-3c5.724-4.932 9.497-5.68 16.938-5.312&quot;/&gt;&lt;path fill=&quot;#AA9450&quot; d=&quot;M133.5 76.75C136 77 136 77 138 79c.313 2.5.313 2.5 0 5-3 2-3 2-5.625 1.688C130 85 130 85 129 84c-.187-2.437-.187-2.437 0-5 2-2 2-2 4.5-2.25&quot;/&gt;&lt;/svg&gt;\n\n\nBgRemover - 在线图片去底工具 - 将纯色背景的图片转换为背景透明的图片\nhttps://www.aigei.com/bgremover/\n\n转化为SVG\nhttps://www.freeconvert.com/\n</code></pre>\n<h1 id=\"灵感来源\"><a href=\"#灵感来源\" class=\"headerlink\" title=\"灵感来源\"></a>灵感来源</h1><p><a href=\"https://cloud.tencent.com.cn/developer/article/2406985?areaId=106001\">群晖NAS使用Docker部署大语言模型Llama 2结合内网穿透实现公网访问本地GPT聊天服务</a></p>\n<p>docker 部署 Liama</p>\n<p><a href=\"https://github.com/LlamaFamily/Llama-Chinese\">https://github.com/LlamaFamily/Llama-Chinese</a></p>","categories":[{"name":"ollama","path":"api/categories/ollama.json"}],"tags":[{"name":"AI","path":"api/tags/AI.json"},{"name":"Llama 3","path":"api/tags/Llama 3.json"},{"name":"tts","path":"api/tags/tts.json"}]}